{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c512b373-7dc1-4af2-a772-425cc60b20b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume text successfully loaded.\n",
      "### Barbara Hidalgo-Sotelo\n",
      "\n",
      "**Data Scientist & Technical Consultant | Passionate about Enterprise Data Management initiatives | Knowledge Graph enthusiast **\n",
      "\n",
      "Email: barbs@balex.com  \n",
      "Website: www.barbhs.com  \n",
      "Location: Austin, TX  \n",
      "\n",
      "---\n",
      "\n",
      "**Summary**  \n",
      "An MIT-trained data scientist with expertise in behavioral research, statistics, machine learning, and management consulting. Experienced in healthcare, federal agencies, and risk management. A personable leader and team player who thrives in cross-disciplinary environments where creativity and flexibility are crucial. Key strengths include leadership, project management, and advanced technical skills.\n",
      "\n",
      "---\n",
      "\n",
      "**Experience**\n",
      "\n",
      "**Senior Data Scientist, Metric5 Consulting**  \n",
      "*01/2021 - 01/2023 (Remote, Client based in Washington DC)*  \n",
      "- Collaborated with a federal regulatory agency to implement the 2021 Federal Data Strategy and Open Government Data Act, enhancing data transparency and accessibility.\n",
      "- Developed a proof-of-concept reporting dashboard integrating ServiceNow, COTS software, and PowerBI, significantly improving the visualization and management of data access requests.\n",
      "\n",
      "**Project Manager - Digital Transformation, Inflective, Inc.**  \n",
      "*01/2017 - 01/2019 (Remote, Client based in Parsippany, NJ)*  \n",
      "- Led a digital transformation project to optimize the adjudication of 4M medical bills annually, resulting in a 30% increase in processing efficiency and significant cost savings.\n",
      "- Co-led Lean Six-Sigma workshops at a multi-billion dollar risk management company, identifying and implementing operational improvements that reduced processing times by 25%.\n",
      "- Introduced a machine learning approach to automate the classification of medical bills, training a decision tree model using Python and Scikit-learn, which matched the performance of human coders.\n",
      "\n",
      "**Research Project Manager - Eye Tracking, MediaScience**  \n",
      "*01/2017 - 01/2017 (Austin, TX)*  \n",
      "- Supervised experimental data collection of eye tracking in naturalistic environments, providing insights into viewer engagement for media industry clients.\n",
      "- Analyzed biometric data, including GSR and facial expressions, delivering customized reports that enhanced client advertising strategies.\n",
      "\n",
      "**Technical Consultant - Web-based Software, Persis Consulting**  \n",
      "*01/2014 - 01/2017 (Remote)*  \n",
      "- Documented software requirements for private-sector consulting clients in the finance and healthcare industries, ensuring alignment with business needs.\n",
      "- Managed QA/QC testing for web-based products, enhancing software reliability and performance.\n",
      "- Created non-technical documentation of web app architecture, facilitating understanding and communication among stakeholders.\n",
      "- Developed comprehensive end-user training, including a wiki and video resources, significantly improving user adoption and satisfaction.\n",
      "\n",
      "**Research Engineer/Scientist, College of Communications, University of Texas at Austin**  \n",
      "*01/2013 - 01/2016 (Austin, TX)*  \n",
      "- Developed a Matlab software package for secure data collection and transmission in a longitudinal study on bilingual language development, contributing to advancements in the field.\n",
      "- Created an algorithm for extracting speech onset time from recorded speech, incorporating a human-validation mechanism to ensure accuracy.\n",
      "- Designed a user-friendly GUI for data analysis, enabling efficient and accurate data processing by research staff.\n",
      "\n",
      "---\n",
      "\n",
      "**Projects**\n",
      "\n",
      "**How-to Build a DIY Temperature Sensor Fleet (2020)**  \n",
      "[Project Link](http://dagny099.github.io/temp-sensor-00/)  \n",
      "- Developed a workflow for visualizing home-generated data from multiple Arduino-powered temperature sensors, enabling real-time monitoring and analysis.\n",
      "- Utilized AWS for data storage and SQL for database management, running a web server for interactive visualization. This project demonstrated practical IoT applications and overcame challenges in sensor calibration and data integration.\n",
      "\n",
      "**Modeling Search for People in 900 Scenes (2009)**  \n",
      "[Project Link](http://olivalab.mit.edu/SearchModels)  \n",
      "- Recorded and analyzed eye movements of observers searching for people in 912 outdoor scenes, providing insights into human visual attention.\n",
      "- Conducted spatial and temporal analyses, utilizing a Bayesian learning model for predictive modeling.\n",
      "- Published findings in a journal article cited by 412 publications as of 07/01/2023, significantly impacting the field of visual cognition.\n",
      "\n",
      "---\n",
      "\n",
      "**Technical Skills**\n",
      "\n",
      "**Programming Languages**  \n",
      "- Python, Matlab, R, SQL, Git, JavaScript, HTML/CSS, Bash script, Neo4j\n",
      "\n",
      "**Data Visualization/Frameworks**  \n",
      "- PowerBI, Tableau, Plotly, Matplotlib, Streamlit, Dash, Seaborn, D3.js\n",
      "\n",
      "**AI/ML Packages**  \n",
      "- scipy, scikit-learn, tensorflow, pyspark, opencv, beautifulsoup, spacy, networkx\n",
      "\n",
      "---\n",
      "\n",
      "**Education**\n",
      "\n",
      "**PhD, Cognitive Science**  \n",
      "Massachusetts Institute of Technology (01/2005 - 01/2011)\n",
      "\n",
      "**BS, Electrical Engineering**  \n",
      "University of Texas at Austin\n",
      "\n",
      "**BS, Biology**  \n",
      "University of Texas at Austin\n",
      "\n",
      "---\n",
      "\n",
      "**Certifications**\n",
      "\n",
      "**Certified Data Management Professional (CDMP)**  \n",
      "Issued by DAMA International, March 2024\n",
      "\n",
      "**AWS Certified Cloud Practitioner**  \n",
      "Issued by Amazon Web Services, June 2023\n",
      "\n",
      "**Open Knowledge Graph Certified**  \n",
      "Issued by EDM Council, November 2022\n",
      "\n",
      "**DCAM V2 Accredited**  \n",
      "Issued by EDM Council, October 2021\n",
      "\n",
      "---\n",
      "\n",
      "**Strengths**\n",
      "\n",
      "**Data Scientist with Business Acumen**  \n",
      "- Co-founded a healthcare business in 2014. Skilled in Agile, Six-Sigma, and multi-project management. Motto: \"If you understand it, you can improve it.\"\n",
      "\n",
      "**Collaborative Leader and Team Player**  \n",
      "- Believes in synergy for greater impact. Effective coaching and teamwork lead to collective success and learning.\n",
      "\n",
      "**Passionate about Data Democratization**  \n",
      "- Committed to empowering individuals to make data-informed decisions, driving innovation.\n",
      "\n",
      "**Eligible for US Security Clearance**\n",
      "\n",
      "---\n",
      "\n",
      "**Incorporated Insights from Research Summary:**\n",
      "\n",
      "**Eye Movement Research and Visual Attention**  \n",
      "- Investigated how visual attention is linked to eye movements and how context-specific learning influences eye movements and attention.\n",
      "- Conducted research on combining bottom-up visual information and top-down scene knowledge during visual search tasks.\n",
      "- Developed computational models to predict individual eye movement patterns and determine visually or cognitively salient regions in scenes.\n",
      "\n",
      "**Publications and Posters**  \n",
      "- Authored numerous publications and presented posters at various conferences, showcasing research on eye movements, visual search, and contextual priors in object search.\n",
      "- Key publications include:\n",
      "  - \"Person, place, and past influence eye movements during visual search\" (2010)\n",
      "  - \"Modeling Search for People in 900 Scenes: A combined source model of eye guidance\" (2009)\n",
      "  - \"Why do we miss rare targets? Exploring the boundaries of the low prevalence effect\" (2008)\n",
      "  - \"Human Learning of Contextual Priors for Object Search: Where does the time go?\" (2005)\n",
      "\n",
      "**Teaching and Public Speaking**  \n",
      "- Taught and served as a TA at MIT, utilizing public speaking and technical writing skills to deliver clear and concise information.\n",
      "- Presented over eight poster presentations and authored more than 20 peer-reviewed publications with 500+ citations.\n",
      "- Current president of the Bilingual Lady Toastmasters club, practicing and participating in public speaking goals with members.\n",
      "\n",
      "---\n",
      "\n",
      "### Summary for Review:\n",
      "\n",
      "**Key Elements:**\n",
      "- **Interdisciplinary Experience:** Spanning business consulting, cognitive science, machine learning, and visual attention research.\n",
      "- **Technical Expertise:** Proficient in Python, MATLAB, R, SQL, and various data visualization and AI/ML tools.\n",
      "- **Initiative and Impact:** Proven ability to take initiative and implement innovative solutions, such as automating manual processes using machine learning.\n",
      "- **Communication and Collaboration:** Strong skills in communicating complex technical concepts to non-technical audiences and working collaboratively with diverse teams.\n",
      "- **Leadership and Teaching:** Experience in leading projects, teaching, and public speaking, with a track record of effective mentorship and communication.\n",
      "\n",
      "**Skills and Experiences:**\n",
      "- **Programming and Technical Skills:** Python, MATLAB, R, SQL, Git, JavaScript, HTML/CSS, Bash script.\n",
      "- **Data Visualization and Frameworks:** PowerBI, Tableau, Plotly, Matplotlib, Streamlit, Dash, Seaborn, D3.js.\n",
      "- **AI/ML Packages:** scipy, scikit-learn, tensorflow, pyspark, opencv, beautifulsoup, spacy, networkx.\n",
      "- **Certifications:** AWS Certified Cloud Practitioner, Open Knowledge Graph Certified, DCAM V2 Accredited.\n",
      "- **Research and Publications:** Extensive research experience with numerous publications and citations.\n",
      "- **Leadership and Initiative:** Proven leadership in various roles, including project management and business transformation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the file path\n",
    "file_path = \"RESUME.txt\"\n",
    "\n",
    "# Try to read the resume text from the file with error handling\n",
    "try:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        resume_text = file.read()\n",
    "    print(\"Resume text successfully loaded.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {file_path} was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Print the resume text to verify\n",
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0c015c-e797-4144-98fc-b2d0c9206efb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "job_desc = 'The Role SGS is looking for an experienced and innovative Sr. Data Scientist to join our team to help create the next generation of artificial intelligence solutions that will help our customers make well-informed decisions and support critical missions. At SGS, you will immerse yourself in cutting-edge research and work with the latest technologies to deliver value in the Industrial IoT and Defense spaces.  Responsibilities:  Building models to solve specific problems Processing, cleansing, and verifying the integrity of data used for analysis Feature engineering using various techniques for the enhancement of data Performing feature selection on original and generated dat Using machine learning tools to develop and train models Performing efficacy testing of the models Building automated tools that enable the data scientist to more effectively perform tasks such as data cleaning, feature generation, feature selection, or model building Performing ad-hoc analysis and presenting results in a clear manner Working with a team to help solve new, never-before-solved challenges across multiple industries Presenting concepts and findings to non-technical audiences, such as company leadership or our customers Required Qualifications:  US Citizenship Understanding and experience using machine learning techniques and algorithms, including but not limited to: transformers, clustering, tree-based methods, neural networks, anomaly detection and more Hands-on experience with data wrangling, feature engineering, model building, evaluation, and visualization. Fluency in Python programming and related machine learning tools (such as NumPy, Pandas, scikit-learn, NLTK, and SpaCy), deep learning frameworks (such as PyTorch), and SQL-like query languages Good applied statistics skills, such as distributions, statistical testing, etc. Experience with both graph and vector databases. ArangoDB and Elastic or similar Familiarity with advanced NLP methods, such as large language models (LLMs), retrieval augmented generation (RAG), fine-tuning or domain-adaptation of NLP models using pre-trained LLMs (such as Hugging Face). Familiarity with document parsing techniques and optical character recognition tools (Tesseract). Graduate degree (or equivalent industry experience), in Computer Science, Statistics, Physics, Mathematics, Neuroscience, Linguistics, Electrical Engineering, Economics, or a related scientific discipline'\n",
    "user_name = 'Barbara Hidalgo-Sotelo'\n",
    "company = 'SparkCognition'\n",
    "manager = 'Hiring Manager'\n",
    "role = 'Senior Data Scientist'\n",
    "referral = 'LinkedIn'\n",
    "ai_temp = .5\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  #model=\"gpt-3.5-turbo-16k\", \n",
    "  model = \"gpt-3.5-turbo\",\n",
    "  temperature=ai_temp,\n",
    "  messages = [\n",
    "    {\"role\": \"user\", \"content\" : f\"You will need to generate a cover letter based on specific resume and a job description\"},\n",
    "    {\"role\": \"user\", \"content\" : f\"My resume text: {resume_text}\"},\n",
    "    {\"role\": \"user\", \"content\" : f\"The job description is: {job_desc}\"},\n",
    "    {\"role\": \"user\", \"content\" : f\"The candidate's name to include on the cover letter: {user_name}\"},\n",
    "    {\"role\": \"user\", \"content\" : f\"The job title/role : {role}\"},\n",
    "    {\"role\": \"user\", \"content\" : f\"The hiring manager is: {manager}\"},\n",
    "    {\"role\": \"user\", \"content\" : f\"How you heard about the opportunity: {referral}\"},\n",
    "    {\"role\": \"user\", \"content\" : f\"The company to which you are generating the cover letter for: {company}\"},\n",
    "    {\"role\": \"user\", \"content\" : f\"The cover letter should have three content paragraphs\"},\n",
    "    {\"role\": \"user\", \"content\" : f\"\"\" \n",
    "    In the first paragraph focus on the following: you will convey who you are, what position you are interested in, and where you heard\n",
    "    about it, and summarize what you have to offer based on the above resume\n",
    "    \"\"\"},\n",
    "        {\"role\": \"user\", \"content\" : f\"\"\" \n",
    "    In the second paragraph focus on why the candidate is a great fit drawing parallels between the experience included in the resume \n",
    "    and the qualifications on the job description.\n",
    "    \"\"\"},\n",
    "            {\"role\": \"user\", \"content\" : f\"\"\" \n",
    "    In the 3RD PARAGRAPH: Conclusion\n",
    "    Restate your interest in the organization and/or job and summarize what you have to offer and thank the reader for their time and consideration.\n",
    "    \"\"\"},\n",
    "    {\"role\": \"user\", \"content\" : f\"\"\" \n",
    "    note that contact information may be found in the included resume text and use and/or summarize specific resume context for the letter\n",
    "        \"\"\"},\n",
    "    {\"role\": \"user\", \"content\" : f\"Use {user_name} as the candidate\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\" : f\"Generate a specific cover letter based on the above. Generate the response and include appropriate spacing between the paragraph text\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb2763e1-cfff-460c-8a21-e02eab6892e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft_2024-06-20_pm\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Example value for the variable\n",
    "company_name = \"Microsoft\"\n",
    "\n",
    "today_date = datetime.today().strftime('%Y-%m-%d') ## Get today's date\n",
    "current_hour = datetime.now().hour  ## Get the current hour\n",
    "time_suffix = \"am\" if current_hour < 12 else \"pm\"  ## Determine if it's AM or PM\n",
    "\n",
    "result_string = f\"{company_name}_{today_date}_{time_suffix}\"\n",
    "print(result_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7945dfc5-51b4-4305-bbf1-311741dc4a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbfe2cc-d4bd-4073-ac53-d460397610cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to extract applicant information from the resume\n",
    "def extract_applicant_info(resume_text):\n",
    "    completion = client.chat.completions.create(\n",
    "      model = \"gpt-3.5-turbo\",\n",
    "      temperature=1,\n",
    "      response_format={ \"type\": \"json_object\" },\n",
    "      messages = [\n",
    "          {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
    "          {\"role\": \"user\", \"content\": f\"Based only on an applicants RESUME below, extract this data about the applicant: NAME, EMAIL, ADDRESS, PHONE NUMBER, and SKILLS\"},\n",
    "          {\"role\": \"user\", \"content\": f\"If any of these elements are unclear or ambiguous, you can use UNSURE in place of the extracted value.\"},\n",
    "          {\"role\": \"user\", \"content\": f\"You MUST respond with a python dictionary containing the data elements as keys and the extracted values.\"},\n",
    "          {\"role\": \"user\", \"content\": f\"Here is the document: {resume_text}\"}\n",
    "      ]\n",
    "    )\n",
    "    return json.loads(completion.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa6fade-1376-41b0-83ab-940e3a4c5e2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "823784f6-d031-4b70-a092-9227b50528f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NAME': 'Barbara Hidalgo-Sotelo',\n",
       " 'EMAIL': 'barbs@balex.com',\n",
       " 'ADDRESS': 'Austin, TX',\n",
       " 'PHONE NUMBER': 'UNSURE',\n",
       " 'SKILLS': {'Programming Languages': ['Python',\n",
       "   'Matlab',\n",
       "   'R',\n",
       "   'SQL',\n",
       "   'Git',\n",
       "   'JavaScript',\n",
       "   'HTML/CSS',\n",
       "   'Bash Script'],\n",
       "  'Data Visualization/Frameworks': ['PowerBI',\n",
       "   'Tableau',\n",
       "   'Plotly',\n",
       "   'Matplotlib',\n",
       "   'Streamlit',\n",
       "   'Dash',\n",
       "   'Seaborn',\n",
       "   'D3.js'],\n",
       "  'AI/ML Packages': ['scipy',\n",
       "   'scikit-learn',\n",
       "   'tensorflow',\n",
       "   'pyspark',\n",
       "   'opencv',\n",
       "   'beautifulsoup',\n",
       "   'spacy',\n",
       "   'networkx']}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "info = extract_applicant_info(resume_text)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5d37d-0c60-4e83-9cc6-bb6130f614a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23420d51-8ff5-4b9a-a61f-43a1614e21af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "ABOUT THE JOB\n",
      "--------------\n",
      "Are you passionate about data, problem solving, distributed systems, and being on the forefront of driving innovations and efficiencies at a massive scale? If so, the Microsoft Azure Storage team might be a great fit for you.\n",
      "\n",
      "Azure Storage, a cornerstone of Microsoft Azure, offers a robust and scalable platform for global customers to store and manage their data. With a focus on performance, reliability, durability, and security, Azure Storage provides a suite of services including Blob Storage, File Storage, Queue Storage, and Table Storage, each designed to meet the diverse needs of our customers’ modern data workloads. We have grown tremendously, with several Exabytes of data stored on our platform, and are designing and building systems for Zettabyte scale to support the anticipated demand for the coming years.\n",
      "\n",
      "As we continue to innovate and expand our capabilities, we are looking for Data Scientist II who can leverage data to solve high–impact business problems. In this role, you will have the opportunity to use machine learning techniques and statistical analyses to experiment with data and push the boundaries of how much value we can create for both our customers and the business. You will be able to use the insights you gain to help shape and strengthen Azure Storage’s technical and business strategy, as well as to have a direct impact on storage efficiency by collaborating with our brightest engineers across the Azure stack to deliver end-to-end results.\n",
      "\n",
      "Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond. If you share our values, love working with data, and want to solve some of the most exciting challenges on a massive product like Azure storage, this could be the perfect position for you.\n",
      "\n",
      "--------------\n",
      "RESPONSIBILITIES\n",
      "--------------\n",
      "\n",
      "\n",
      "\t•\tYou will understand where to acquire the data necessary for your project plan and use querying, visualization, and reporting techniques to describe that data. You’ll also explore data for key attributes and collaborate with others to perform data science experiments using established methodologies for end-to-end scenarios.\n",
      "\t•\tYou will study the system, and design methodologies to model components of distributed systems. You will also build predictive models, conduct experiments and analyze data to gain insights into customer usage patterns, and the quality and health of products.\n",
      "\t•\tYou will understand modeling techniques, select the correct tool and approach to complete objectives, and evaluate the output for statistical and business significance. You’ll also analyze model performance and incorporate customer feedback into its evaluation.\n",
      "\t•\tYou will understand the current state of the industry, including current trends, so that you can contribute to thought leadership best practices. You’ll also write efficient code for a specific feature, and develop a working expertise of proper debugging techniques.\n",
      "\t•\tYou will understand each customer’s business goals and learn best practices for identifying growth opportunities. You’ll also examine projects through a customer-oriented focus, and manage customer expectations regarding project progress.\n",
      "\t•\tYou will collaborate with others on building and deploying statistical models, applying machine learning techniques for targeted solutions and effectively communicating the analysis and findings through interactive visualizations, documents, and presentations.\n",
      "\t•\tEmbody our Culture and Values  ",
      "\n",
      "--------------\n",
      "QUALIFICATIONS\n",
      "--------------\n",
      "\n",
      "Required Qualifications:\n",
      "\n",
      "\t•\tDoctorate in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field\n",
      "\t•\tOR Master's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 1+ year(s) data-science experience (e.g., managing structured and unstructured data, applying statistical tec\n",
      "\t•\tOR Bachelor's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 2+ years data-science experience (e.g., managing structured and unstructured data, applying statistical tec\n",
      "\t•\tOR equivalent experience.\n",
      "\t•\t1+ year(s) customer-facing, project-delivery experience, professional services, and/or consulting experience.\n",
      "\t•\t1+ year(s) experience developing end-to-end Machine Learning systems.\n",
      "\t•\t1+ year(s) experience with open-source, cloud-based platforms, Microsoft Azure, or any other public/private cloud platforms.\n",
      "\n",
      "Other Requirements\n",
      "\n",
      "\t•\tAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: \n",
      "\t•\tMicrosoft Cloud Background Check: This position will be required to pass the Microsoft Cloud Background Check upon hire/transfer and every two years thereafter.\n",
      "\n",
      "Preferred Qualifications\n",
      "\n",
      "\t•\tDoctorate in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science,\n",
      "\t•\tOR related field AND 1+ year(s) data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)\n",
      "\t•\tOR Master's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science,\n",
      "\t•\tOR related field AND 3+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)\n",
      "\t•\tOR Bachelor's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science,\n",
      "\t•\tOR related field AND 5+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)\n",
      "\t•\tOR equivalent experience.\n",
      "\t•\tUnderstanding of public cloud design patterns and considerations in the areas of Distributed Storage Systems, Big-Data, Data Mining, Information Retrieval.\n",
      "\t•\tAn efficient candidate would:\n",
      "\t•\tHave good interpersonal, oral, and written communication and presentation skills, and the ability to communicate complex findings simply.\n",
      "\t•\tEnjoy discovering and solving problems, proactively seeking clarification of requirements and direction, being a self-starter who takes responsibility when required.\n",
      "\t•\tBe able to explore different directions for analyses and be able to quickly adapt and change direction based on the data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "filename='microsoft_data_scientist_two.txt'\n",
    "jobFolder='saved_JOBS'\n",
    "\n",
    "with open(jobFolder+os.path.sep+filename, 'r') as file:\n",
    "    text = file.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b214a3-5182-4d5b-9f4d-84570283d07e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba06bff-ffd3-4880-b2fd-6aa5fde53d73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".going-meta24",
   "language": "python",
   "name": ".going-meta24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
